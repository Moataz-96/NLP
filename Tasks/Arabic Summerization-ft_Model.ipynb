{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ar.300.vec.gz\n",
    "# !wget https://liquidtelecom.dl.sourceforge.net/project/easc-corpus/EASC/EASC.zip\n",
    "#!unzip EASC.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<fasttext.FastText._FastText at 0x7f11c4540e10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fasttext.util\n",
    "fasttext.util.download_model('ar', if_exists='ignore')  # English\n",
    "ft = fasttext.load_model('cc.ar.300.bin')\n",
    "fasttext.util.reduce_model(ft, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_labels',\n",
       " '_words',\n",
       " 'f',\n",
       " 'get_analogies',\n",
       " 'get_dimension',\n",
       " 'get_input_matrix',\n",
       " 'get_input_vector',\n",
       " 'get_label_id',\n",
       " 'get_labels',\n",
       " 'get_line',\n",
       " 'get_meter',\n",
       " 'get_nearest_neighbors',\n",
       " 'get_output_matrix',\n",
       " 'get_sentence_vector',\n",
       " 'get_subword_id',\n",
       " 'get_subwords',\n",
       " 'get_word_id',\n",
       " 'get_word_vector',\n",
       " 'get_words',\n",
       " 'is_quantized',\n",
       " 'labels',\n",
       " 'predict',\n",
       " 'quantize',\n",
       " 'save_model',\n",
       " 'set_args',\n",
       " 'set_matrices',\n",
       " 'test',\n",
       " 'test_label',\n",
       " 'words']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import unicodedata\n",
    "import difflib\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "from barbar import Bar\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'Data/'\n",
    "models_path = 'Models/'\n",
    "if not os.path.exists(data_path):    \n",
    "    os.makedirs(data_path)\n",
    "    os.makedirs(data_path+\"EASC/\")\n",
    "if not os.path.exists(models_path):    \n",
    "    os.makedirs(models_path)\n",
    "    \n",
    "path_art = data_path + \"EASC/Articles/\"\n",
    "path_mturk = data_path + \"EASC/MTurk/\"\n",
    "\n",
    "if not os.path.exists(path_art):    \n",
    "    shutil.move(\"EASC/EASC-UTF-8/Articles\",data_path+\"EASC/\")\n",
    "if not os.path.exists(path_mturk):    \n",
    "    shutil.move(\"EASC/EASC-UTF-8/MTurk\",data_path+\"EASC/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if torch.cuda.is_available():\n",
    "#     device = torch.device(\"cuda\")\n",
    "# else:\n",
    "#     device = torch.device('cpu')\n",
    "# print(torch.cuda.get_device_name('cuda'))\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From Moustafa Tohamy\n",
    "\n",
    "punctuations_list = '''`÷×؛<>_()*&^%][ـ/\"'{}~¦+|!”…“–ـ'''\n",
    "\n",
    "arabic_diacritics = re.compile(\"\"\"\n",
    "                             ّ    | # Tashdid\n",
    "                             َ    | # Fatha\n",
    "                             ً    | # Tanwin Fath\n",
    "                             ُ    | # Damma\n",
    "                             ٌ    | # Tanwin Damm\n",
    "                             ِ    | # Kasra\n",
    "                             ٍ    | # Tanwin Kasr\n",
    "                             ْ    | # Sukun\n",
    "                             ـ     # Tatwil/Kashida\n",
    "                         \"\"\", re.VERBOSE)\n",
    "\n",
    "def remove_links(text):\n",
    "  text = re.sub(r'http\\S+', '', text)\n",
    "  return text\n",
    "\n",
    "def normalize_arabic(text):\n",
    "    text = re.sub(\"[إأآا]\", \"ا\", text)\n",
    "    text = re.sub(\"ى\", \"ي\", text)\n",
    "    text = re.sub(\"ؤ\", \"ء\", text)\n",
    "    text = re.sub(\"ئ\", \"ء\", text)\n",
    "    text = re.sub(\"ة\", \"ه\", text)\n",
    "    text = re.sub(\"گ\", \"ك\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def whitespace(text):\n",
    "    return text.replace('.',' . ').replace('،',' ، ').replace(':',' : ').replace('?',' ? ')\n",
    "\n",
    "def remove_diacritics(text):\n",
    "    text = re.sub(arabic_diacritics, '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "\n",
    "\n",
    "def remove_repeating_char(text):\n",
    "    return re.sub(r'(.)\\1+', r'\\1', text)\n",
    "\n",
    "def pre_process_document(text):\n",
    "    text = remove_links(text)\n",
    "    text = remove_punctuations(text)\n",
    "    text = whitespace(text)\n",
    "    text = remove_diacritics(text)\n",
    "    text = remove_repeating_char(text)\n",
    "    return text\n",
    "\n",
    "pre_process_corpus = np.vectorize(pre_process_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# word = difflib.get_close_matches('اسم', ft.words ,n=1, cutoff=0)[0] #most similar string to fasttext\n",
    "# print(\"word :\",word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "files = []\n",
    "num_of_files = 0\n",
    "articles = [f for f in listdir(path_art)]\n",
    "mturk = [f for f in listdir(path_mturk)]\n",
    "num_of_files = 2 + len(articles) + len(mturk)\n",
    "for i in articles:\n",
    "    article = [f for f in listdir(path_art+i)]\n",
    "    mturk = [f for f in listdir(path_mturk+i)]\n",
    "    num_of_files += len(article)\n",
    "    num_of_files += len(mturk)\n",
    "    for _ in range(len(mturk)):\n",
    "        files.append(([path_art+i+\"/\" + file for file in article][0],path_mturk+i+\"/\"+mturk[_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Data/EASC/Articles/Topic123/Science and Technology (10).TXT', 'Data/EASC/MTurk/Topic123/D08010.M.250.A.2.B')\n",
      "verified num of files : 1226\n"
     ]
    }
   ],
   "source": [
    "print(files[50])\n",
    "print(\"verified num of files :\",num_of_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_easc:\n",
    "    def __init__(self,files,preprocess = pre_process_corpus):\n",
    "        self.X = []\n",
    "        self.Y = []\n",
    "        self.MAX_LENGTH = 600\n",
    "        self.target_length = 100\n",
    "        self.read_files(files)\n",
    "        \n",
    "    def read_files(self,files):\n",
    "        i = 0\n",
    "        for x_file,y_file in files:           \n",
    "                \n",
    "            with open(x_file, 'r') as content_file:\n",
    "                content_file_x = str(pre_process_corpus(content_file.read()))\n",
    "                x_i = []\n",
    "                for word in content_file_x.split():\n",
    "                    word_id = ft.get_word_id(word)\n",
    "                    if(word_id < 0):\n",
    "                        word_id = word_id*-1\n",
    "                    x_i.append([word_id])\n",
    "                x_i.append([ft.get_word_id('eos')])\n",
    "                self.X.append(torch.tensor(x_i,device=device))\n",
    "                \n",
    "            with open(y_file, 'r') as content_file:\n",
    "                content_file_y = str(pre_process_corpus(content_file.read()))\n",
    "                y_i = []\n",
    "                for word in content_file_y.split():\n",
    "                    word_id = ft.get_word_id(word)\n",
    "                    if(word_id < 0):\n",
    "                        word_id = word_id*-1\n",
    "                    y_i.append([word_id])\n",
    "                y_i.append([ft.get_word_id('eos')])\n",
    "                self.Y.append(torch.tensor(y_i,device=device))\n",
    "                \n",
    "            i += 1\n",
    "            if(i%10 == 0):\n",
    "                print(\"file :\",(i) ,\" Done , Loading ...\")\n",
    "            \n",
    "                \n",
    "    def read_sentences(self,sentences):\n",
    "        data = []\n",
    "        for sent in sentences:\n",
    "            x_i = []\n",
    "            for word in sent.split():\n",
    "                word_id = ft.get_word_id(word)\n",
    "                if(word_id < 0):\n",
    "                    word_id = word_id*-1\n",
    "                x_i.append([word_id])\n",
    "            x_i.append([ft.get_word_id('eos')])\n",
    "            data.append(torch.tensor(x_i,device=device))\n",
    "        return data   \n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx],self.Y[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file : 10  Done , Loading ...\n",
      "file : 20  Done , Loading ...\n",
      "file : 30  Done , Loading ...\n",
      "file : 40  Done , Loading ...\n",
      "file : 50  Done , Loading ...\n",
      "file : 60  Done , Loading ...\n",
      "file : 70  Done , Loading ...\n",
      "file : 80  Done , Loading ...\n",
      "file : 90  Done , Loading ...\n",
      "file : 100  Done , Loading ...\n",
      "file : 110  Done , Loading ...\n",
      "file : 120  Done , Loading ...\n",
      "file : 130  Done , Loading ...\n",
      "file : 140  Done , Loading ...\n",
      "file : 150  Done , Loading ...\n",
      "file : 160  Done , Loading ...\n",
      "file : 170  Done , Loading ...\n",
      "file : 180  Done , Loading ...\n",
      "file : 190  Done , Loading ...\n",
      "file : 200  Done , Loading ...\n",
      "file : 210  Done , Loading ...\n",
      "file : 220  Done , Loading ...\n",
      "file : 230  Done , Loading ...\n",
      "file : 240  Done , Loading ...\n",
      "file : 250  Done , Loading ...\n",
      "file : 260  Done , Loading ...\n",
      "file : 270  Done , Loading ...\n",
      "file : 280  Done , Loading ...\n",
      "file : 290  Done , Loading ...\n",
      "file : 300  Done , Loading ...\n",
      "file : 310  Done , Loading ...\n",
      "file : 320  Done , Loading ...\n",
      "file : 330  Done , Loading ...\n",
      "file : 340  Done , Loading ...\n",
      "file : 350  Done , Loading ...\n",
      "file : 360  Done , Loading ...\n",
      "file : 370  Done , Loading ...\n",
      "file : 380  Done , Loading ...\n",
      "file : 390  Done , Loading ...\n",
      "file : 400  Done , Loading ...\n",
      "file : 410  Done , Loading ...\n",
      "file : 420  Done , Loading ...\n",
      "file : 430  Done , Loading ...\n",
      "file : 440  Done , Loading ...\n",
      "file : 450  Done , Loading ...\n",
      "file : 460  Done , Loading ...\n",
      "file : 470  Done , Loading ...\n",
      "file : 480  Done , Loading ...\n",
      "file : 490  Done , Loading ...\n",
      "file : 500  Done , Loading ...\n",
      "file : 510  Done , Loading ...\n",
      "file : 520  Done , Loading ...\n",
      "file : 530  Done , Loading ...\n",
      "file : 540  Done , Loading ...\n",
      "file : 550  Done , Loading ...\n",
      "file : 560  Done , Loading ...\n",
      "file : 570  Done , Loading ...\n",
      "file : 580  Done , Loading ...\n",
      "file : 590  Done , Loading ...\n",
      "file : 600  Done , Loading ...\n",
      "file : 610  Done , Loading ...\n",
      "file : 620  Done , Loading ...\n",
      "file : 630  Done , Loading ...\n",
      "file : 640  Done , Loading ...\n",
      "file : 650  Done , Loading ...\n",
      "file : 660  Done , Loading ...\n",
      "file : 670  Done , Loading ...\n",
      "file : 680  Done , Loading ...\n",
      "file : 690  Done , Loading ...\n",
      "file : 700  Done , Loading ...\n",
      "file : 710  Done , Loading ...\n",
      "file : 720  Done , Loading ...\n",
      "file : 730  Done , Loading ...\n",
      "file : 740  Done , Loading ...\n",
      "file : 750  Done , Loading ...\n",
      "file : 760  Done , Loading ...\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset_easc(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "765\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[      1],\n",
      "         [   9668],\n",
      "         [ 976622],\n",
      "         [1588674],\n",
      "         [  12040],\n",
      "         [   1345],\n",
      "         [   7785],\n",
      "         [  10061],\n",
      "         [   8044],\n",
      "         [      7],\n",
      "         [   1103],\n",
      "         [   2063],\n",
      "         [  16956],\n",
      "         [    456],\n",
      "         [  14557],\n",
      "         [      5],\n",
      "         [    129],\n",
      "         [   1630],\n",
      "         [      1],\n",
      "         [     15],\n",
      "         [   1563],\n",
      "         [      7],\n",
      "         [    532],\n",
      "         [  13585],\n",
      "         [ 155316],\n",
      "         [    619],\n",
      "         [   1363],\n",
      "         [   1012],\n",
      "         [     25],\n",
      "         [  13585],\n",
      "         [ 155316],\n",
      "         [    619],\n",
      "         [  13612],\n",
      "         [  17569],\n",
      "         [   1832],\n",
      "         [   1140],\n",
      "         [   2071],\n",
      "         [   5142],\n",
      "         [   3890],\n",
      "         [   5158],\n",
      "         [  74633],\n",
      "         [ 682493],\n",
      "         [   4646],\n",
      "         [ 138724],\n",
      "         [   3159],\n",
      "         [   1410],\n",
      "         [  16875],\n",
      "         [    468],\n",
      "         [    343],\n",
      "         [   2045],\n",
      "         [    135],\n",
      "         [   2445],\n",
      "         [   1885],\n",
      "         [  32107],\n",
      "         [   2001],\n",
      "         [  20675],\n",
      "         [  16875],\n",
      "         [   3947],\n",
      "         [ 369115],\n",
      "         [   1158],\n",
      "         [  77844],\n",
      "         [    718],\n",
      "         [  10010],\n",
      "         [     52],\n",
      "         [    114],\n",
      "         [      7],\n",
      "         [   3555],\n",
      "         [     86],\n",
      "         [   5270],\n",
      "         [  12661],\n",
      "         [      4],\n",
      "         [  13945],\n",
      "         [   1427],\n",
      "         [     16],\n",
      "         [   4886],\n",
      "         [   2248],\n",
      "         [   5334],\n",
      "         [    859],\n",
      "         [  74633],\n",
      "         [   5040],\n",
      "         [   2695],\n",
      "         [      5],\n",
      "         [    177],\n",
      "         [   1563],\n",
      "         [  15850],\n",
      "         [   1055],\n",
      "         [     27],\n",
      "         [   5830],\n",
      "         [    198],\n",
      "         [  37227],\n",
      "         [  11465],\n",
      "         [  54305],\n",
      "         [  13612],\n",
      "         [ 122973],\n",
      "         [  37227],\n",
      "         [   8600],\n",
      "         [    619],\n",
      "         [   1012],\n",
      "         [      2],\n",
      "         [      2],\n",
      "         [      2],\n",
      "         [ 268327],\n",
      "         [  60279],\n",
      "         [     36],\n",
      "         [    432],\n",
      "         [     60],\n",
      "         [ 216975],\n",
      "         [      7],\n",
      "         [   2445],\n",
      "         [   1885],\n",
      "         [     25],\n",
      "         [   2815],\n",
      "         [     15],\n",
      "         [   5671],\n",
      "         [   1941],\n",
      "         [     25],\n",
      "         [   9650],\n",
      "         [   8044],\n",
      "         [   1120],\n",
      "         [   3555],\n",
      "         [     25],\n",
      "         [    593],\n",
      "         [      5],\n",
      "         [    809],\n",
      "         [     25],\n",
      "         [    201],\n",
      "         [     75],\n",
      "         [  15869],\n",
      "         [      2],\n",
      "         [      2],\n",
      "         [      2],\n",
      "         [    381],\n",
      "         [ 750538],\n",
      "         [   4105],\n",
      "         [    207],\n",
      "         [     86],\n",
      "         [    531],\n",
      "         [      7],\n",
      "         [  66338],\n",
      "         [   1798],\n",
      "         [      5],\n",
      "         [  94321],\n",
      "         [   6793],\n",
      "         [   1563],\n",
      "         [      9],\n",
      "         [    157],\n",
      "         [      7],\n",
      "         [   4496],\n",
      "         [  15958],\n",
      "         [   1130],\n",
      "         [    168],\n",
      "         [   7698],\n",
      "         [  28498],\n",
      "         [     27],\n",
      "         [   6618],\n",
      "         [      7],\n",
      "         [     37],\n",
      "         [     52],\n",
      "         [ 139010],\n",
      "         [      7],\n",
      "         [   3890],\n",
      "         [      7],\n",
      "         [    437],\n",
      "         [   3932],\n",
      "         [     25],\n",
      "         [    437],\n",
      "         [   1390],\n",
      "         [   6491],\n",
      "         [  11656],\n",
      "         [     25],\n",
      "         [      7],\n",
      "         [ 327641],\n",
      "         [   1356],\n",
      "         [     25],\n",
      "         [   1410],\n",
      "         [     25],\n",
      "         [  85040],\n",
      "         [      1],\n",
      "         [      7],\n",
      "         [   3555],\n",
      "         [      4],\n",
      "         [    357],\n",
      "         [     22],\n",
      "         [   3144],\n",
      "         [    152],\n",
      "         [     15],\n",
      "         [   1563],\n",
      "         [  13530],\n",
      "         [  10006],\n",
      "         [ 176247],\n",
      "         [     24],\n",
      "         [   3893],\n",
      "         [    166],\n",
      "         [  46274],\n",
      "         [ 234729],\n",
      "         [    212],\n",
      "         [     24],\n",
      "         [ 333166],\n",
      "         [      7],\n",
      "         [  78640],\n",
      "         [  32908],\n",
      "         [   9477],\n",
      "         [  66338],\n",
      "         [  22100],\n",
      "         [  29271],\n",
      "         [  17328],\n",
      "         [    676],\n",
      "         [      1],\n",
      "         [ 355193],\n",
      "         [ 217290],\n",
      "         [  19715],\n",
      "         [  10158],\n",
      "         [    680],\n",
      "         [     37],\n",
      "         [   6013],\n",
      "         [   8030],\n",
      "         [    162],\n",
      "         [      2],\n",
      "         [      2],\n",
      "         [      2],\n",
      "         [  16280],\n",
      "         [    686],\n",
      "         [   4549],\n",
      "         [     22],\n",
      "         [   2721],\n",
      "         [      7],\n",
      "         [   3390],\n",
      "         [    859],\n",
      "         [   8600],\n",
      "         [   1504],\n",
      "         [   1103],\n",
      "         [   2063],\n",
      "         [  15393],\n",
      "         [     15],\n",
      "         [   5040],\n",
      "         [   3814],\n",
      "         [      7],\n",
      "         [   8044],\n",
      "         [     58],\n",
      "         [      5],\n",
      "         [  21681],\n",
      "         [  78160],\n",
      "         [   4174],\n",
      "         [   6858],\n",
      "         [      9],\n",
      "         [    249],\n",
      "         [ 345050],\n",
      "         [  29187],\n",
      "         [  14222],\n",
      "         [     18],\n",
      "         [  22932],\n",
      "         [   2100],\n",
      "         [  92398],\n",
      "         [      4],\n",
      "         [   1024],\n",
      "         [     51],\n",
      "         [    295],\n",
      "         [    185],\n",
      "         [   1869],\n",
      "         [  11656],\n",
      "         [    915],\n",
      "         [   8030],\n",
      "         [      7],\n",
      "         [    249],\n",
      "         [    228],\n",
      "         [     22],\n",
      "         [   2721],\n",
      "         [     15],\n",
      "         [  48408],\n",
      "         [    469],\n",
      "         [      4],\n",
      "         [  80764],\n",
      "         [     15],\n",
      "         [   1427],\n",
      "         [     81],\n",
      "         [   2704],\n",
      "         [      7],\n",
      "         [  13379],\n",
      "         [   8645],\n",
      "         [     69],\n",
      "         [   2175],\n",
      "         [  68988],\n",
      "         [1396230],\n",
      "         [   2175],\n",
      "         [  68988],\n",
      "         [      2],\n",
      "         [      2],\n",
      "         [      2],\n",
      "         [  97942],\n",
      "         [   5173],\n",
      "         [   1504],\n",
      "         [   1563],\n",
      "         [    553],\n",
      "         [   7785],\n",
      "         [  10061],\n",
      "         [   8044],\n",
      "         [     18],\n",
      "         [   7673],\n",
      "         [   1029],\n",
      "         [    712],\n",
      "         [  13612],\n",
      "         [      2],\n",
      "         [      2],\n",
      "         [      2],\n",
      "         [    106],\n",
      "         [  76286],\n",
      "         [      5],\n",
      "         [   1967],\n",
      "         [  13612],\n",
      "         [     76],\n",
      "         [  39984],\n",
      "         [   8645],\n",
      "         [    596],\n",
      "         [  25593],\n",
      "         [   1826],\n",
      "         [   4513],\n",
      "         [ 553844],\n",
      "         [  15886],\n",
      "         [     15],\n",
      "         [    537],\n",
      "         [  13146],\n",
      "         [     58],\n",
      "         [    712],\n",
      "         [   1650],\n",
      "         [     25],\n",
      "         [   8920],\n",
      "         [  12737],\n",
      "         [     25],\n",
      "         [    629],\n",
      "         [   4484],\n",
      "         [      4],\n",
      "         [  38062],\n",
      "         [   1567],\n",
      "         [     15],\n",
      "         [   1427],\n",
      "         [   3438],\n",
      "         [     16],\n",
      "         [   4886],\n",
      "         [    337],\n",
      "         [   2248],\n",
      "         [   5334],\n",
      "         [    859],\n",
      "         [  74633],\n",
      "         [   5040],\n",
      "         [      2],\n",
      "         [      2],\n",
      "         [      2],\n",
      "         [   1212],\n",
      "         [   8348],\n",
      "         [   2695],\n",
      "         [   8645],\n",
      "         [    596],\n",
      "         [    179],\n",
      "         [      5],\n",
      "         [    177],\n",
      "         [   1563],\n",
      "         [  15850],\n",
      "         [   1055],\n",
      "         [     63],\n",
      "         [   2066],\n",
      "         [   1427],\n",
      "         [  50517],\n",
      "         [   2324],\n",
      "         [    101],\n",
      "         [   1427],\n",
      "         [     41],\n",
      "         [      7],\n",
      "         [ 210173],\n",
      "         [  19825],\n",
      "         [   8645],\n",
      "         [     69],\n",
      "         [    169],\n",
      "         [    284],\n",
      "         [   3377],\n",
      "         [      2],\n",
      "         [   1024],\n",
      "         [     51],\n",
      "         [    295],\n",
      "         [  14547],\n",
      "         [   2063],\n",
      "         [   2747],\n",
      "         [  17214],\n",
      "         [     25],\n",
      "         [  15462],\n",
      "         [   5164],\n",
      "         [  16470],\n",
      "         [  72345],\n",
      "         [  72783],\n",
      "         [    101],\n",
      "         [   3869],\n",
      "         [   3021],\n",
      "         [  34173],\n",
      "         [  33836],\n",
      "         [    994],\n",
      "         [   1542],\n",
      "         [     86],\n",
      "         [  32247],\n",
      "         [   3932],\n",
      "         [  68342],\n",
      "         [   5067],\n",
      "         [  22483],\n",
      "         [      5],\n",
      "         [   3613],\n",
      "         [   1487],\n",
      "         [   3219],\n",
      "         [    128],\n",
      "         [ 170192],\n",
      "         [   3735],\n",
      "         [   2989],\n",
      "         [    554],\n",
      "         [      7],\n",
      "         [  52236],\n",
      "         [   7373],\n",
      "         [ 110010],\n",
      "         [      2],\n",
      "         [      2],\n",
      "         [      2],\n",
      "         [  10737],\n",
      "         [     15],\n",
      "         [  25178],\n",
      "         [ 368853],\n",
      "         [   1869],\n",
      "         [   2045],\n",
      "         [      7],\n",
      "         [ 597269],\n",
      "         [ 678403],\n",
      "         [ 611978],\n",
      "         [   3159],\n",
      "         [  38558],\n",
      "         [     76],\n",
      "         [  11207],\n",
      "         [   3969],\n",
      "         [      2],\n",
      "         [  10737],\n",
      "         [  38418],\n",
      "         [  42888],\n",
      "         [   1367],\n",
      "         [     22],\n",
      "         [    513],\n",
      "         [   8290],\n",
      "         [     67],\n",
      "         [     97],\n",
      "         [    340],\n",
      "         [     41],\n",
      "         [      7],\n",
      "         [ 210173],\n",
      "         [     15],\n",
      "         [    219],\n",
      "         [    107],\n",
      "         [   6443],\n",
      "         [   4108],\n",
      "         [   2806],\n",
      "         [    284],\n",
      "         [    335],\n",
      "         [  16168],\n",
      "         [  92398],\n",
      "         [    135],\n",
      "         [     21],\n",
      "         [   6530],\n",
      "         [      5],\n",
      "         [   2365],\n",
      "         [  10061],\n",
      "         [   8044],\n",
      "         [     75],\n",
      "         [  10140],\n",
      "         [    135],\n",
      "         [   8792],\n",
      "         [    107],\n",
      "         [  16689],\n",
      "         [  17985],\n",
      "         [  10668],\n",
      "         [    203],\n",
      "         [1001006],\n",
      "         [    247],\n",
      "         [  10482],\n",
      "         [  13717],\n",
      "         [   5335],\n",
      "         [      2],\n",
      "         [      2],\n",
      "         [     28],\n",
      "         [  23035],\n",
      "         [      7],\n",
      "         [     21],\n",
      "         [  22470],\n",
      "         [  63103],\n",
      "         [      9],\n",
      "         [    323],\n",
      "         [   6825],\n",
      "         [     75],\n",
      "         [  12230],\n",
      "         [    104],\n",
      "         [    427],\n",
      "         [     86],\n",
      "         [   1983],\n",
      "         [      9],\n",
      "         [   6930],\n",
      "         [    438],\n",
      "         [      7],\n",
      "         [    568],\n",
      "         [     15],\n",
      "         [ 106373],\n",
      "         [ 563800],\n",
      "         [  19672],\n",
      "         [   1869],\n",
      "         [   2045],\n",
      "         [ 226570],\n",
      "         [  74633],\n",
      "         [ 682493],\n",
      "         [     67],\n",
      "         [  53600],\n",
      "         [      9],\n",
      "         [  15964],\n",
      "         [   1130],\n",
      "         [     78],\n",
      "         [    137],\n",
      "         [   2092],\n",
      "         [      5],\n",
      "         [   3469],\n",
      "         [   4796],\n",
      "         [     75],\n",
      "         [  51814],\n",
      "         [      2],\n",
      "         [      2],\n",
      "         [      2],\n",
      "         [ 151396],\n",
      "         [   2070],\n",
      "         [    135],\n",
      "         [    427],\n",
      "         [    962],\n",
      "         [    814],\n",
      "         [     26],\n",
      "         [   7657],\n",
      "         [ 713367],\n",
      "         [    531],\n",
      "         [     39],\n",
      "         [   3365],\n",
      "         [     67],\n",
      "         [     76],\n",
      "         [     75],\n",
      "         [  74938],\n",
      "         [     25],\n",
      "         [  18954],\n",
      "         [    340],\n",
      "         [     41],\n",
      "         [   3290],\n",
      "         [  78640],\n",
      "         [    531],\n",
      "         [      7],\n",
      "         [  32908],\n",
      "         [     27],\n",
      "         [     78],\n",
      "         [   1443],\n",
      "         [    128],\n",
      "         [   2523],\n",
      "         [    335],\n",
      "         [     89],\n",
      "         [   8181],\n",
      "         [ 563800],\n",
      "         [   1216],\n",
      "         [   2365],\n",
      "         [  10061],\n",
      "         [   8044],\n",
      "         [      7],\n",
      "         [   1869],\n",
      "         [   2045],\n",
      "         [   4646],\n",
      "         [  11229],\n",
      "         [     25],\n",
      "         [   4323],\n",
      "         [      7],\n",
      "         [  31750],\n",
      "         [  97934],\n",
      "         [    138],\n",
      "         [  78070],\n",
      "         [   1306],\n",
      "         [   4485],\n",
      "         [   5208],\n",
      "         [      5],\n",
      "         [   5144],\n",
      "         [   3607],\n",
      "         [      2],\n",
      "         [ 688135]]]), tensor([[[  11517],\n",
      "         [   9668],\n",
      "         [ 976622],\n",
      "         [      1],\n",
      "         [  12040],\n",
      "         [   1345],\n",
      "         [   7785],\n",
      "         [  10061],\n",
      "         [   8044],\n",
      "         [      7],\n",
      "         [      1],\n",
      "         [  16956],\n",
      "         [    456],\n",
      "         [  14557],\n",
      "         [      5],\n",
      "         [    129],\n",
      "         [   1630],\n",
      "         [      1],\n",
      "         [     49],\n",
      "         [   1563],\n",
      "         [      7],\n",
      "         [      1],\n",
      "         [ 155316],\n",
      "         [    619],\n",
      "         [   1363],\n",
      "         [   1012],\n",
      "         [    154],\n",
      "         [  13585],\n",
      "         [ 155316],\n",
      "         [    619],\n",
      "         [  13612],\n",
      "         [  17569],\n",
      "         [      1],\n",
      "         [   2071],\n",
      "         [   5142],\n",
      "         [  19027],\n",
      "         [   5158],\n",
      "         [     22],\n",
      "         [      2],\n",
      "         [ 268327],\n",
      "         [  60279],\n",
      "         [     36],\n",
      "         [    331],\n",
      "         [     60],\n",
      "         [ 216975],\n",
      "         [      1],\n",
      "         [   1885],\n",
      "         [    154],\n",
      "         [   2815],\n",
      "         [     49],\n",
      "         [   5671],\n",
      "         [   6924],\n",
      "         [    154],\n",
      "         [   9650],\n",
      "         [   8044],\n",
      "         [   1120],\n",
      "         [   3555],\n",
      "         [    154],\n",
      "         [    593],\n",
      "         [      1],\n",
      "         [    154],\n",
      "         [    201],\n",
      "         [     75],\n",
      "         [  15869],\n",
      "         [      2],\n",
      "         [   1024],\n",
      "         [     51],\n",
      "         [   1632],\n",
      "         [  14547],\n",
      "         [   2063],\n",
      "         [   2747],\n",
      "         [  17214],\n",
      "         [    154],\n",
      "         [  15462],\n",
      "         [   5164],\n",
      "         [  16470],\n",
      "         [ 224880],\n",
      "         [1546011],\n",
      "         [   3869],\n",
      "         [   3021],\n",
      "         [  34173],\n",
      "         [  33836],\n",
      "         [    994],\n",
      "         [   1542],\n",
      "         [     86],\n",
      "         [  32247],\n",
      "         [   3932],\n",
      "         [  68342],\n",
      "         [   5067],\n",
      "         [  74156],\n",
      "         [      1],\n",
      "         [   1487],\n",
      "         [   3219],\n",
      "         [    128],\n",
      "         [ 170192],\n",
      "         [   3735],\n",
      "         [   2989],\n",
      "         [   2879],\n",
      "         [      7],\n",
      "         [  52236],\n",
      "         [      1],\n",
      "         [      2],\n",
      "         [  10737],\n",
      "         [  38418],\n",
      "         [  42888],\n",
      "         [   1367],\n",
      "         [     22],\n",
      "         [    513],\n",
      "         [   8290],\n",
      "         [     67],\n",
      "         [     97],\n",
      "         [   1492],\n",
      "         [     41],\n",
      "         [      7],\n",
      "         [ 210173],\n",
      "         [     49],\n",
      "         [    219],\n",
      "         [      1],\n",
      "         [   4108],\n",
      "         [   2806],\n",
      "         [    743],\n",
      "         [    335],\n",
      "         [  16168],\n",
      "         [  92398],\n",
      "         [    135],\n",
      "         [     21],\n",
      "         [  28696],\n",
      "         [      5],\n",
      "         [   7759],\n",
      "         [      1],\n",
      "         [     75],\n",
      "         [  10140],\n",
      "         [    135],\n",
      "         [   8792],\n",
      "         [    107],\n",
      "         [  16689],\n",
      "         [  17985],\n",
      "         [  10668],\n",
      "         [    203],\n",
      "         [1001006],\n",
      "         [      1],\n",
      "         [  13717],\n",
      "         [   5335],\n",
      "         [      2],\n",
      "         [     28],\n",
      "         [  43222],\n",
      "         [      7],\n",
      "         [     21],\n",
      "         [  22470],\n",
      "         [  63103],\n",
      "         [      9],\n",
      "         [    323],\n",
      "         [   6825],\n",
      "         [     75],\n",
      "         [  31431],\n",
      "         [    495],\n",
      "         [    427],\n",
      "         [     86],\n",
      "         [  24113],\n",
      "         [      9],\n",
      "         [      1],\n",
      "         [      7],\n",
      "         [    568],\n",
      "         [     49],\n",
      "         [ 106373],\n",
      "         [ 563800],\n",
      "         [  19672],\n",
      "         [   5403],\n",
      "         [   2045],\n",
      "         [ 226570],\n",
      "         [ 208086],\n",
      "         [      1],\n",
      "         [  53600],\n",
      "         [      9],\n",
      "         [  15964],\n",
      "         [   1130],\n",
      "         [     78],\n",
      "         [    137],\n",
      "         [   2092],\n",
      "         [      5],\n",
      "         [   3469],\n",
      "         [   4796],\n",
      "         [     75],\n",
      "         [ 155370],\n",
      "         [      2],\n",
      "         [ 151396],\n",
      "         [   2070],\n",
      "         [    135],\n",
      "         [    427],\n",
      "         [    962],\n",
      "         [    814],\n",
      "         [     26],\n",
      "         [   7657],\n",
      "         [ 713367],\n",
      "         [    531],\n",
      "         [     39],\n",
      "         [   3365],\n",
      "         [     67],\n",
      "         [      1],\n",
      "         [  74938],\n",
      "         [    154],\n",
      "         [  18954],\n",
      "         [   1492],\n",
      "         [     41],\n",
      "         [   6797],\n",
      "         [  78640],\n",
      "         [    531],\n",
      "         [      7],\n",
      "         [  32908],\n",
      "         [     27],\n",
      "         [     78],\n",
      "         [   1443],\n",
      "         [      1],\n",
      "         [    335],\n",
      "         [     89],\n",
      "         [   8181],\n",
      "         [ 563800],\n",
      "         [   1216],\n",
      "         [   7759],\n",
      "         [  10061],\n",
      "         [   8044],\n",
      "         [      7],\n",
      "         [   5403],\n",
      "         [   2045],\n",
      "         [   4646],\n",
      "         [      1],\n",
      "         [   4323],\n",
      "         [      7],\n",
      "         [  31750],\n",
      "         [      2],\n",
      "         [ 688135]]])]\n",
      "(tensor([[      1],\n",
      "        [ 129499],\n",
      "        [     58],\n",
      "        [   1664],\n",
      "        [  27409],\n",
      "        [ 102984],\n",
      "        [      9],\n",
      "        [   2790],\n",
      "        [   2181],\n",
      "        [  15689],\n",
      "        [  12169],\n",
      "        [    590],\n",
      "        [ 157830],\n",
      "        [    680],\n",
      "        [    729],\n",
      "        [ 129499],\n",
      "        [1042118],\n",
      "        [ 171302],\n",
      "        [    125],\n",
      "        [  16494],\n",
      "        [      2],\n",
      "        [      5],\n",
      "        [    126],\n",
      "        [    355],\n",
      "        [    174],\n",
      "        [    359],\n",
      "        [  16494],\n",
      "        [  25015],\n",
      "        [   2076],\n",
      "        [  93777],\n",
      "        [  32897],\n",
      "        [      4],\n",
      "        [    789],\n",
      "        [   3411],\n",
      "        [ 272450],\n",
      "        [ 451782],\n",
      "        [  77067],\n",
      "        [ 187814],\n",
      "        [1271598],\n",
      "        [    590],\n",
      "        [ 157830],\n",
      "        [    680],\n",
      "        [    729],\n",
      "        [ 129499],\n",
      "        [      4],\n",
      "        [   3044],\n",
      "        [      5],\n",
      "        [    170],\n",
      "        [1178301],\n",
      "        [1386377],\n",
      "        [ 163621],\n",
      "        [   6798],\n",
      "        [   3496],\n",
      "        [      2],\n",
      "        [    106],\n",
      "        [   2686],\n",
      "        [     18],\n",
      "        [   4835],\n",
      "        [   4319],\n",
      "        [  23562],\n",
      "        [   4331],\n",
      "        [    642],\n",
      "        [    129],\n",
      "        [      7],\n",
      "        [     41],\n",
      "        [      9],\n",
      "        [   6256],\n",
      "        [   2076],\n",
      "        [  39720],\n",
      "        [   4331],\n",
      "        [      7],\n",
      "        [   1417],\n",
      "        [   2049],\n",
      "        [     77],\n",
      "        [   2705],\n",
      "        [      2],\n",
      "        [     40],\n",
      "        [  14893],\n",
      "        [    855],\n",
      "        [  31256],\n",
      "        [      4],\n",
      "        [    604],\n",
      "        [  60582],\n",
      "        [      7],\n",
      "        [    922],\n",
      "        [   3639],\n",
      "        [ 132675],\n",
      "        [  77630],\n",
      "        [     46],\n",
      "        [    798],\n",
      "        [    845],\n",
      "        [      4],\n",
      "        [   5291],\n",
      "        [   2120],\n",
      "        [   1166],\n",
      "        [  17544],\n",
      "        [ 263431],\n",
      "        [      4],\n",
      "        [  34870],\n",
      "        [   1859],\n",
      "        [  37256],\n",
      "        [  31202],\n",
      "        [      5],\n",
      "        [  11722],\n",
      "        [   4288],\n",
      "        [  18550],\n",
      "        [      4],\n",
      "        [   8769],\n",
      "        [   1296],\n",
      "        [  27075],\n",
      "        [ 109465],\n",
      "        [   2184],\n",
      "        [      5],\n",
      "        [    347],\n",
      "        [    176],\n",
      "        [   2405],\n",
      "        [     14],\n",
      "        [   1929],\n",
      "        [      5],\n",
      "        [    172],\n",
      "        [    370],\n",
      "        [  17377],\n",
      "        [  11895],\n",
      "        [  40161],\n",
      "        [      9],\n",
      "        [  13711],\n",
      "        [  86422],\n",
      "        [  22674],\n",
      "        [      5],\n",
      "        [ 301612],\n",
      "        [     18],\n",
      "        [   6709],\n",
      "        [   2076],\n",
      "        [  94435],\n",
      "        [  38782],\n",
      "        [  19032],\n",
      "        [    140],\n",
      "        [   3437],\n",
      "        [   1388],\n",
      "        [ 420736],\n",
      "        [  21002],\n",
      "        [  21682],\n",
      "        [ 416268],\n",
      "        [      1],\n",
      "        [     89],\n",
      "        [   8498],\n",
      "        [   7679],\n",
      "        [   1688],\n",
      "        [      9],\n",
      "        [  46352],\n",
      "        [      2],\n",
      "        [      9],\n",
      "        [   6293],\n",
      "        [   7066],\n",
      "        [    786],\n",
      "        [   2521],\n",
      "        [   5426],\n",
      "        [   1635],\n",
      "        [ 309867],\n",
      "        [   3056],\n",
      "        [      5],\n",
      "        [  13973],\n",
      "        [     14],\n",
      "        [  56204],\n",
      "        [ 713423],\n",
      "        [      1],\n",
      "        [   6502],\n",
      "        [      7],\n",
      "        [  13493],\n",
      "        [   1029],\n",
      "        [      1],\n",
      "        [      7],\n",
      "        [  43096],\n",
      "        [ 139637],\n",
      "        [      2],\n",
      "        [ 149970],\n",
      "        [  71612],\n",
      "        [      9],\n",
      "        [ 294898],\n",
      "        [  32386],\n",
      "        [    786],\n",
      "        [   9106],\n",
      "        [      4],\n",
      "        [    501],\n",
      "        [  54852],\n",
      "        [    190],\n",
      "        [     24],\n",
      "        [ 247389],\n",
      "        [      7],\n",
      "        [  13770],\n",
      "        [  31656],\n",
      "        [ 136702],\n",
      "        [  71612],\n",
      "        [    265],\n",
      "        [   2692],\n",
      "        [   7741],\n",
      "        [  43096],\n",
      "        [  53940],\n",
      "        [      2],\n",
      "        [   1020],\n",
      "        [  71612],\n",
      "        [ 804601],\n",
      "        [1841974],\n",
      "        [      5],\n",
      "        [  11010],\n",
      "        [    363],\n",
      "        [    323],\n",
      "        [    714],\n",
      "        [     76],\n",
      "        [ 469148],\n",
      "        [      7],\n",
      "        [   4219],\n",
      "        [   1058],\n",
      "        [      7],\n",
      "        [    696],\n",
      "        [   6039],\n",
      "        [      5],\n",
      "        [    415],\n",
      "        [    236],\n",
      "        [  15595],\n",
      "        [   2073],\n",
      "        [   1817],\n",
      "        [  59988],\n",
      "        [  28285],\n",
      "        [     53],\n",
      "        [   6505],\n",
      "        [   2120],\n",
      "        [    581],\n",
      "        [    653],\n",
      "        [ 113665],\n",
      "        [     70],\n",
      "        [    687],\n",
      "        [     18],\n",
      "        [   3746],\n",
      "        [      4],\n",
      "        [  23476],\n",
      "        [      9],\n",
      "        [    786],\n",
      "        [   9106],\n",
      "        [  10580],\n",
      "        [  13493],\n",
      "        [      4],\n",
      "        [ 606914],\n",
      "        [  20697],\n",
      "        [   9247],\n",
      "        [    214],\n",
      "        [      7],\n",
      "        [   2120],\n",
      "        [   6695],\n",
      "        [   2159],\n",
      "        [    212],\n",
      "        [  94549],\n",
      "        [      4],\n",
      "        [    106],\n",
      "        [   7066],\n",
      "        [    786],\n",
      "        [   9106],\n",
      "        [    522],\n",
      "        [   1487],\n",
      "        [   1216],\n",
      "        [   2828],\n",
      "        [   1449],\n",
      "        [   5486],\n",
      "        [      5],\n",
      "        [  11349],\n",
      "        [  78763],\n",
      "        [1423115],\n",
      "        [   3085],\n",
      "        [     97],\n",
      "        [    151],\n",
      "        [    303],\n",
      "        [  15595],\n",
      "        [      4],\n",
      "        [   2866],\n",
      "        [   1098],\n",
      "        [  71612],\n",
      "        [      5],\n",
      "        [    434],\n",
      "        [   5043],\n",
      "        [      5],\n",
      "        [     33],\n",
      "        [    370],\n",
      "        [      7],\n",
      "        [    407],\n",
      "        [     84],\n",
      "        [ 237904],\n",
      "        [   1058],\n",
      "        [    765],\n",
      "        [      7],\n",
      "        [    323],\n",
      "        [   3501],\n",
      "        [   8801],\n",
      "        [   3341],\n",
      "        [  43139],\n",
      "        [      7],\n",
      "        [    573],\n",
      "        [   5486],\n",
      "        [  15695],\n",
      "        [1034726],\n",
      "        [ 236056],\n",
      "        [    786],\n",
      "        [      9],\n",
      "        [ 293838],\n",
      "        [  30939],\n",
      "        [  13493],\n",
      "        [      2],\n",
      "        [     60],\n",
      "        [  78056],\n",
      "        [    786],\n",
      "        [  30939],\n",
      "        [  13493],\n",
      "        [     27],\n",
      "        [  25526],\n",
      "        [   9721],\n",
      "        [    630],\n",
      "        [      4],\n",
      "        [   6413],\n",
      "        [ 148721],\n",
      "        [  17574],\n",
      "        [  22213],\n",
      "        [  13244],\n",
      "        [  40229],\n",
      "        [    120],\n",
      "        [  28560],\n",
      "        [     16],\n",
      "        [  15343],\n",
      "        [      9],\n",
      "        [   7825],\n",
      "        [  43014],\n",
      "        [  46476],\n",
      "        [  17526],\n",
      "        [  11134],\n",
      "        [      5],\n",
      "        [   2495],\n",
      "        [   1807],\n",
      "        [    558],\n",
      "        [     60],\n",
      "        [    708],\n",
      "        [  48595],\n",
      "        [   5180],\n",
      "        [   1487],\n",
      "        [    549],\n",
      "        [      4],\n",
      "        [   2866],\n",
      "        [   8058],\n",
      "        [    786],\n",
      "        [      5],\n",
      "        [     51],\n",
      "        [     16],\n",
      "        [    848],\n",
      "        [   2402],\n",
      "        [      4],\n",
      "        [    256],\n",
      "        [   2967],\n",
      "        [      9],\n",
      "        [    876],\n",
      "        [    484],\n",
      "        [     69],\n",
      "        [ 132229],\n",
      "        [      5],\n",
      "        [  98982],\n",
      "        [      4],\n",
      "        [     27],\n",
      "        [  10709],\n",
      "        [    968],\n",
      "        [ 143896],\n",
      "        [   6355],\n",
      "        [    522],\n",
      "        [   6031],\n",
      "        [      4],\n",
      "        [  15449],\n",
      "        [      9],\n",
      "        [    876],\n",
      "        [    798],\n",
      "        [    413],\n",
      "        [  30080],\n",
      "        [      4],\n",
      "        [   6683],\n",
      "        [   2309],\n",
      "        [    876],\n",
      "        [   2967],\n",
      "        [     67],\n",
      "        [     41],\n",
      "        [      7],\n",
      "        [    484],\n",
      "        [  18217],\n",
      "        [     27],\n",
      "        [ 150443],\n",
      "        [      5],\n",
      "        [  94321],\n",
      "        [     27],\n",
      "        [  50690],\n",
      "        [      5],\n",
      "        [ 137294],\n",
      "        [   3038],\n",
      "        [  34335],\n",
      "        [  30915],\n",
      "        [      5],\n",
      "        [     53],\n",
      "        [    351],\n",
      "        [  16494],\n",
      "        [   5780],\n",
      "        [  14511],\n",
      "        [   7849],\n",
      "        [      9],\n",
      "        [    786],\n",
      "        [   4530],\n",
      "        [    377],\n",
      "        [    353],\n",
      "        [      7],\n",
      "        [    407],\n",
      "        [     84],\n",
      "        [  18745],\n",
      "        [  62261],\n",
      "        [     16],\n",
      "        [  57761],\n",
      "        [      2],\n",
      "        [      1],\n",
      "        [  71612],\n",
      "        [     49],\n",
      "        [  22326],\n",
      "        [     78],\n",
      "        [   7354],\n",
      "        [      5],\n",
      "        [   7573],\n",
      "        [   5486],\n",
      "        [ 137263],\n",
      "        [      4],\n",
      "        [1108426],\n",
      "        [      5],\n",
      "        [    198],\n",
      "        [  11928],\n",
      "        [  16494],\n",
      "        [  46476],\n",
      "        [1137502],\n",
      "        [      5],\n",
      "        [   2495],\n",
      "        [   1807],\n",
      "        [     36],\n",
      "        [   4272],\n",
      "        [     77],\n",
      "        [  11836],\n",
      "        [    786],\n",
      "        [    604],\n",
      "        [  12141],\n",
      "        [   5518],\n",
      "        [    574],\n",
      "        [   1020],\n",
      "        [  12817],\n",
      "        [  25824],\n",
      "        [  22656],\n",
      "        [      7],\n",
      "        [     56],\n",
      "        [  13182],\n",
      "        [  56385],\n",
      "        [  77994],\n",
      "        [   5518],\n",
      "        [   1412],\n",
      "        [   2507],\n",
      "        [      7],\n",
      "        [  30639],\n",
      "        [   1839],\n",
      "        [      2],\n",
      "        [     14],\n",
      "        [      5],\n",
      "        [    415],\n",
      "        [    309],\n",
      "        [  10622],\n",
      "        [  34989],\n",
      "        [   1594],\n",
      "        [   1159],\n",
      "        [   1757],\n",
      "        [  14672],\n",
      "        [      9],\n",
      "        [  90376],\n",
      "        [ 119837],\n",
      "        [ 287493],\n",
      "        [   4977],\n",
      "        [      2],\n",
      "        [    423],\n",
      "        [   3984],\n",
      "        [     21],\n",
      "        [    734],\n",
      "        [   3256],\n",
      "        [  71612],\n",
      "        [      5],\n",
      "        [   8210],\n",
      "        [     26],\n",
      "        [    786],\n",
      "        [  60092],\n",
      "        [     18],\n",
      "        [    835],\n",
      "        [     16],\n",
      "        [  10084],\n",
      "        [   6764],\n",
      "        [  24087],\n",
      "        [    786],\n",
      "        [  28714],\n",
      "        [     16],\n",
      "        [  40147],\n",
      "        [   7515],\n",
      "        [  44361],\n",
      "        [ 301612],\n",
      "        [     18],\n",
      "        [   3234],\n",
      "        [  31223],\n",
      "        [    381],\n",
      "        [  62471],\n",
      "        [   2663],\n",
      "        [      2],\n",
      "        [  38668],\n",
      "        [  13493],\n",
      "        [  16554],\n",
      "        [    747],\n",
      "        [      9],\n",
      "        [    713],\n",
      "        [      7],\n",
      "        [  49565],\n",
      "        [     60],\n",
      "        [    975],\n",
      "        [    199],\n",
      "        [   1908],\n",
      "        [      2],\n",
      "        [ 688135]]), tensor([[149970],\n",
      "        [ 71612],\n",
      "        [     9],\n",
      "        [294898],\n",
      "        [ 32386],\n",
      "        [   786],\n",
      "        [  9106],\n",
      "        [     4],\n",
      "        [   501],\n",
      "        [349122],\n",
      "        [   190],\n",
      "        [    24],\n",
      "        [247389],\n",
      "        [     7],\n",
      "        [ 13770],\n",
      "        [ 31656],\n",
      "        [136702],\n",
      "        [ 71612],\n",
      "        [   265],\n",
      "        [  2692],\n",
      "        [  7741],\n",
      "        [ 43096],\n",
      "        [ 53940],\n",
      "        [     2],\n",
      "        [688135]]))\n"
     ]
    }
   ],
   "source": [
    "training_pairs = DataLoader(dataset,sampler = RandomSampler(dataset),batch_size = 1)\n",
    "for i in training_pairs:\n",
    "    print(i)\n",
    "    break\n",
    "for i in dataset:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair = dataset[0]\n",
    "# print([idx2word[idx.item()] for idx in list(pair[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, self.hidden_size)\n",
    "        self.embedding.weight.data.copy_(torch.tensor(list(ft.get_input_matrix()[0:2000000])))\n",
    "#         self.embedding.weight.requires_grad = False\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=dataset.MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.embedding.weight.data.copy_(torch.tensor(list(ft.get_input_matrix()[0:2000000])))  \n",
    "#         self.embedding.weight.requires_grad = False\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(models_path,epoch,encoder,decoder):\n",
    "    output_encoder = 'saved_encoder_epoch'+str(epoch)+'.txt'\n",
    "    output_decoder = 'saved_decoder_epoch'+str(epoch)+'.txt'\n",
    "    print(\"Saving encoder model to %s\" % output_encoder)\n",
    "    print(\"Saving decoder model to %s\" % output_encoder)\n",
    "    torch.save(encoder.state_dict(), output_encoder)\n",
    "    torch.save(decoder.state_dict(), output_decoder)\n",
    "    shutil.move(output_encoder,models_path)\n",
    "    shutil.move(output_decoder,models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(models_path,epoch,encoder,decoder):\n",
    "    output_encoder = models_path + 'saved_encoder_epoch'+str(epoch)+'.txt'\n",
    "    output_decoder = models_path + 'saved_decoder_epoch'+str(epoch)+'.txt'\n",
    "    print(\"loading encoder model to %s\" % output_encoder)\n",
    "    print(\"loading decoder model to %s\" % output_encoder)\n",
    "    encoder.load_state_dict(torch.load(output_encoder))\n",
    "    decoder.load_state_dict(torch.load(output_decoder))\n",
    "    return encoder,decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def trainIters(dataset,encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0\n",
    "    plot_loss_total = 0\n",
    "    \n",
    "    max_length = dataset.MAX_LENGTH\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = DataLoader(dataset,sampler = RandomSampler(dataset),batch_size = 1)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        print(\"Iter :\",iter)\n",
    "        for batch,training_pair in enumerate(training_pairs):\n",
    "            input_tensor = training_pair[0][0]\n",
    "            target_tensor = training_pair[1][0]\n",
    "            input_length = input_tensor.size(0)\n",
    "            target_length = target_tensor.size(0)\n",
    "            encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "            loss = 0\n",
    "            encoder_hidden = encoder.initHidden()\n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "        \n",
    "            if(max_length < input_length):\n",
    "                encoder_length = max_length\n",
    "            else:\n",
    "                encoder_length = input_length\n",
    "            \n",
    "\n",
    "            for ei in range(0,encoder_length):\n",
    "                encoder_output, encoder_hidden = encoder(\n",
    "                    input_tensor[ei], encoder_hidden)\n",
    "                encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "            decoder_input = torch.tensor([ft.get_word_id('sos')], device=device)\n",
    "            decoder_hidden = encoder_hidden\n",
    "            use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "            if use_teacher_forcing:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                for di in range(target_length):\n",
    "                    decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                        decoder_input, decoder_hidden, encoder_outputs)\n",
    "                    loss += criterion(decoder_output, target_tensor[di])\n",
    "                    decoder_input = target_tensor[di].detach()  # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                for di in range(target_length):\n",
    "                    decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                        decoder_input, decoder_hidden, encoder_outputs)\n",
    "                    topv, topi = decoder_output.topk(1)\n",
    "                    decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "                    loss += criterion(decoder_output, target_tensor[di])\n",
    "                    if decoder_input.item() == ft.get_word_id('eos'):\n",
    "                        break\n",
    "                loss.backward()\n",
    "\n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "\n",
    "            loss_item = loss.item() / target_length\n",
    "            print(\"Batch \",batch)\n",
    "            print(\"Total loss:\",loss_item)\n",
    "        \n",
    "        save_model(models_path,iter,encoder,decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_dims = 100\n",
    "num_of_words = 2000000\n",
    "hidden_size = num_of_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading encoder model to Models/saved_encoder_epoch1.txt\n",
      "loading decoder model to Models/saved_encoder_epoch1.txt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "unexpected EOF, expected 461614862 more bytes. The file might be corrupted.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-7f5a3d50a80f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mencoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_of_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mattn_decoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttnDecoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_of_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattn_decoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattn_decoder1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mencoder1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-26144148c9ff>\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(models_path, epoch, encoder, decoder)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading decoder model to %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0moutput_encoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_encoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_decoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    707\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_storage_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_should_read_directly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: unexpected EOF, expected 461614862 more bytes. The file might be corrupted."
     ]
    }
   ],
   "source": [
    "encoder1 = EncoderRNN(num_of_words, hidden_size)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, num_of_words, dropout_p=0.1)\n",
    "# encoder1,attn_decoder1 = load_model(models_path,1,encoder1,attn_decoder1)\n",
    "encoder1.to(device)\n",
    "attn_decoder1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter : 1\n",
      "Batch  0\n",
      "Total loss: 14.52703857421875\n",
      "Batch  1\n",
      "Total loss: 14.51861020635933\n",
      "Batch  2\n",
      "Total loss: 14.511962890625\n",
      "Batch  3\n",
      "Total loss: 14.51512378414735\n",
      "Batch  4\n",
      "Total loss: 14.489382418397627\n",
      "Batch  5\n",
      "Total loss: 14.503206863655116\n",
      "Batch  6\n",
      "Total loss: 14.452562604631696\n"
     ]
    }
   ],
   "source": [
    "epoch = 10\n",
    "trainIters(dataset,encoder1, attn_decoder1, epoch, print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(input_tensor,encoder,decoder,max_length=dataset.MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        if(max_length < input_length):\n",
    "            length_encoding = max_length\n",
    "        else:\n",
    "            length_encoding = input_length\n",
    "            \n",
    "        for ei in range(length_encoding):\n",
    "            encoder_output, encoder_hidden = encoder.forward(embedding,input_tensor[ei],encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[ft.get_word_id('sos')]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "        minimum_words = 10\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder.forward(embedding,\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            \n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == ft.get_word_id('eos') and di > minimum_words:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            elif topi.item() == ft.get_word_id('eos') and di < minimum_words:\n",
    "                topv, topi = decoder_output.data.topk(2)\n",
    "                topv = topv[:,-1]\n",
    "                topi = topi[:,-1]\n",
    "                decoded_words.append(ft.words[topi.item()])\n",
    "            else:\n",
    "                decoded_words.append(ft.words[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> . انا اسمي يكون معتز\n",
      "sos الى sos الى sos الى sos الى sos الى eos <EOS>\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe862a49f50>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence = \". انا اسمي يكون معتز\"\n",
    "predict = dataset.read_sentences([sentence])[0]\n",
    "print('>',sentence)\n",
    "output_words, attentions = evaluate(predict,encoder1, attn_decoder1,dataset.MAX_LENGTH)\n",
    "output_sentence = ' '.join(output_words)\n",
    "print(output_sentence)\n",
    "# print('<', )\n",
    "print('')\n",
    "plt.matshow(attentions.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(dataset,encoder, decoder, n=2):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(dataset)\n",
    "        print('>', \" \".join([ft.words[idx.item()] for idx in list(pair[0])]))\n",
    "        print(\"\\n\\n\")\n",
    "        print('=', \" \".join([ft.words[idx.item()] for idx in list(pair[1])]))\n",
    "        output_words, attentions = evaluate(pair[0],encoder, decoder,dataset.MAX_LENGTH)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print(\"\\n\\n\")\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> sos | - اف ب - اعلن مصدر رسمي ان وزير الدولة القطري لشؤون الداخلية الشيخ عبداله بن ناصر بن خليفة آل ثاني قر الثلاثاء اعادة تشكيل الجنة الدائمة لشؤون الجنسية في اطار تطوير | | في البلاد . وذكرت وكالة الانباء القطرية ان الشيخ عبد اله | قرارا وزاريا تم بموجبه اعادة تشكيل الجنة الدائمة لشؤون الجنسية في اطار الجهود المبذولة لتطوير الخدمات الامنية وترقية الاداء في ظل التطور الذي تشهده الوزارة والادارات | . وكان تقرير لهيئة حكومية قطرية لحقوق الانسان نشر الثلاثاء ، اشار الى تجاوزات في ملف حقوق الانسان بينها حالات تعلق بسحب الجنسية وتعذيب ومنع من السفر اضافة الى استمرار | الاجتماعي والاقتصادي | ضد المرأة . وقال التقرير السنوي الاول من نوعه الذي اصدرته الجنة الوطنية لحقوق الانسان الحكومية في قطر ، انه | رصد 149 شكوى والتماسا تلقتها الجنة خلال عام | في هذا المجال . وتحدثت مصادر عدة مؤخرا عن سحب الجنسية من عد من القطرين في اجراء قالت السلطات القطرية انه مجرد تطبيق لقانون الذي يحظر ازدواج الجنسية في حين رد بعض من نزعت جنسيتهم الامر الى ولائهم لامير قطر السابق . eos\n",
      "\n",
      "\n",
      "\n",
      "= sos وذكرت وكالة الانباء القطرية ان الشيخ عبد اله | قرارا وزاريا تم | تشكيل الجنة الدائمة لشؤون الجنسية في اطار الجهود المبذولة | الامنية وترقية الاداء في ظل التطور الذي تشهده الوزارة | . وكان تقرير لهيئة حكومية قطرية لحقوق الانسان نشر الثلاثاء ، اشار الى تجاوزات فيملف حقوق الانسان بينها حالات تعلق بسحب الجنسية وتعذيب ومنع من السفر اضافة | | الاجتماعي والاقتصادي | ضد المراة . eos\n",
      "\n",
      "\n",
      "\n",
      "< sos sos sos sos sos sos sos sos sos sos eos <EOS>\n",
      "\n",
      "> sos | هو آلة تعامل مع البيانات وفقا لمجموعة من التعليمات | . تعد أنواع الحواسيب من حيث طريقة عملها وحجمها . أوائل الحواسيب الإلكترونية كانت في حجم غرفة كبيرة وتستهلك طاقة ماثلة لما يستهلكه بضعة مئات من الحواسيب الشخصية اليوم . 1 من المكن اليوم صنع حواسيب داخل ساعة يد تأخذ طاقتها من بطارية الساعة . ينظر المجتمع إلى الحاسوب الشخصي | المتنقل الحاسوب | على أنهما رمزي عصر المعلومات فهما ما يفكر به معظم الناس عند الحديث عن الحاسوب . على الرغم من هذا فأكثر أشكال الحاسوب استخداما اليوم هي الحواسيب المضمنة . الحواسيب المضمنة حي أجهزة صغيرة وبسيطة تستخدم عادة لتحكم في أجهزة أخرى ، فعلى سبيل المثال يمكنك أن تجدها في آلات تراوح من الطائرات المقاتلة ، و الآليون ، وآلات التصوير الرقمية ولعب الأطفال . حاسوب في ساعة يد . لا يمكن القول بأن الحاسوب هو اختراع بحد ذاته لأنه كان نتاج الكثير من الابتكارات العلمية و التطبيقات الرياضية . الحاسبات متنوعة ، في الواقع إنها آلات معالجة بيانات عالمية . طبقا لفرض | فإن حاسب له قدرة ذات حد أدنى معين يكون بساطة قادر على إنجاز المهام الخاصة بأي حاسب آخر ، بدءا من المساعد الرقمي الشخصي إلى الحاسوب الفائق ، طالما أن الوقت وسعة الذاكرة ليست في الاعتبار . لذلك فإن التصميمات المتماثلة من الحاسب من المكن أن تضبط من أجل مهام تراوح بين معالجة حسابات موظفي الشركات والتحكم في المركبات الفضائية بدون طيار . و بسب التطور التكنولوجي فإن الحاسبات الاليكترونية الحديثة بشكل جبري تكون أكثر قدرة من تلك التي من الأجيال السابقة ظاهرة موصوفة و مشروحة جزئيا بقانون مور . أساسا يعبر مصطلح حاسب عن الشخص الذي يقوم بالحسابات الرقمية و غالبا ما يكون ذلك بمساعدة جهاز حساب ميكانيكي . يوجد أمثلة على أجهزة الحساب البدائية تلك و التي تمثل الأسلاف الأوائل لكمبيوتر ، منها abacus أو المعداد أداة تستخدم الآن في تعليم الاطفال العد و Antikythera mechanism وهو جهاز يوناني قديم كان يستخدم لحساب حركات الكواكب و التأريخ من سنة 87 قبل الميلاد تقريبا . شهدت نهاية العصور الوسطى نشاطا أوروبيا في علمي الرياضيات والهندسة وكان Wilhelm | 1623 الأول من عد من العلماء الاوربين الذي انشاء آلة حاسبة ميكانيكية . تم تدوين abacus المعداد على أنه حاسب بدائي وذلك لانها كانت تشبه الالة الحاسبة في الماضي . في سنة 1801 قام Joseph Marie Jacquard بعمل تحسين لاشكال النولية الموجودة و التي تستخدم مجموعة متالية من الكروت الورقية المثقبة و كأنها برنامج لنسج اشكال معقدة . والنتيجة كانت أن نول Jacquard لم يتم اعتباره وكأنه حاسب حقيقي ولكنه كان خطوة هامة في تطوير الحاسبات الرقمية الحديثة . كان تشارلز باباج أول من فكر و صم حاسب مبرمج بالكامل و ذلك في بدايات سنة 1820 ولكن بسب مجموعة من الحدود التكنولوجية في ذلك الوقت والمحدودية المالية ، و كذلك عدم القدرة على حل مشكلة الإصلاح غير الجيد في تصميمه فإن الجهاز لم يتم بناءه فعليا في حياته . عد من التكنولوجيات و التي اثبت فائدتها لاحقا في الحوسبة ، مثل الكارت المثقب و أنبوبة الصمام ظهرت بنهاية القرن التاسع عشر ، و معالجة البيانات أوتوماتيكيا ذات التدرج الكبير باستخدام الكروت المثقبة تم صنعها باستخدام آلات جدولة و التي تم تصميمها على يد Herman | . خلال النصف الاول من القرن العشرين ، العديد من احتياجات الحسابات العلمية تزداد | ، الحاسبات التماثلية ذات الغرض المخص والتي استخدمت نسخة ميكانيكية او كهربية مباشرة من المسألة كقاعدة في الحساب . اصبحت تلك | غاية في الندرة بعد التطوير الذي طرأ على الحاسب الرقمي المبرمج . eos\n",
      "\n",
      "\n",
      "\n",
      "= sos الحاسوب هو آلة تعامل مع البيانات وفقا لمجموعة من التعليمات | . اوائل الحواسيب الالكترونية كانت في حجم غرفة كبيرة وتستهلك طاقة ماثلة لما يستهلكه بضعة مئات من الحواسيب الشخصية اليوم . ينظر المجتمع الى الحاسوب الشخصي | المتنقل الحاسوب | على انهما رمزي عصر المعلومات فهما ما يفكر به معظم الناس عند الحديث عن الحاسوب . الحواسيب المضمنة حي اجهزة صغيرة وبسيطة تستخدم عادة لتحكم في اجهزة اخرى ، فعلى سبيل المثال يمكنك ان تجدها في آلات تراوح من الطائرات المقاتلة ، و الآليون ، وآلات التصوير الرقمية ولعب الاطفال . لا يمكن القول بان الحاسوب هو اختراع بحد ذاته لانه كان نتاج الكثير من الابتكارات العلمية و التطبيقات الرياضية . طبقا لفرض | فان حاسب له قدرة ذات حد ادنى معين يكون بساطة قادر على انجاز المهام الخاصة باي حاسب آخر ، بدءا من المساعد الرقمي الشخصي الى الحاسوب الفائق ، طالما ان الوقت وسعة الذاكرة ليست في الاعتبار . و بسب التطور التكنولوجي فان الحاسبات الاليكترونية الحديثة بشكل جبري تكون اكثر قدرة من تلك التي من الاجيال السابقة ظاهرة موصوفة و مشروحة جزئيا بقانون مور . يوجد امثلة على اجهزة الحساب البدائية تلك و التي تمثل الاسلاف الاوائل لكمبيوتر ، منها abacus او المعداد اداة تستخدم الآن في تعليم الاطفال العد و Antikythera mechanism وهو جهاز يوناني قديم كان يستخدم لحساب حركات الكواكب و التاريخ من سنة 87 قبل الميلاد ت . تم تدوين abacus المعداد على انه حاسب بدائي وذلك لانها كانت تشبه الالة الحاسبة في الماضي . والنتيجة كانت ان نول Jacquard لم يتم اعتباره وكانه حاسب حقيقي ولكنه كان خطوة هامة في تطوير الحاسبات الرقمية الحديثة . عد من التكنولوجيات و التي اثبت فائدتها لاحقا في الحوسبة ، مثل الكارت المثقب و انبوبة الصمام ظهرت بنهاية القرن التاسع عشر ، و معالجة البيانات اوتوماتيكيا ذات التدرج الكبير باستخدام الكروت المثقبة تم صنعها باستخدام آلات جدولة و التي تم تصميمها على يد | . eos\n",
      "\n",
      "\n",
      "\n",
      "< sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(dataset,encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair = dataset[0]\n",
    "# print([idx2word[idx.item()] for idx in list(pair[0])])\n",
    "# print('>', \" \".join([idx2word[idx.item()] for idx in list(pair[0])]))\n",
    "# print('=', \" \".join([idx2word[idx.item()] for idx in list(pair[1])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    predict = dataset.read_sentences([input_sentence])[0]\n",
    "    output_words, attentions = evaluate(predict,\n",
    "        encoder1, attn_decoder1, dataset.MAX_LENGTH)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)\n",
    "\n",
    "\n",
    "# evaluateAndShowAttention(\" الجمله\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
